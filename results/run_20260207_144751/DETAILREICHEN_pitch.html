<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Entscheider-Benchmark 2026 – Detailanalyse</title>
<style>
:root {
  --primary: #1a1a2e;
  --secondary: #16213e;
  --accent: #e94560;
  --highlight: #0f3460;
  --bg: #f4f5f7;
  --card: #ffffff;
  --text: #2d3436;
  --muted: #636e72;
  --border: #dfe6e9;
  --opus46: #D4780A;
  --opus45: #7C3AED;
  --sonnet: #2563EB;
  --haiku: #059669;
  --green: #10B981;
  --yellow: #F59E0B;
  --red: #EF4444;
}
*, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }
body {
  font-family: -apple-system, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
  background: var(--bg);
  color: var(--text);
  line-height: 1.7;
  font-size: 16px;
}
.hero {
  background: linear-gradient(135deg, var(--primary) 0%, var(--secondary) 50%, var(--highlight) 100%);
  color: #fff;
  padding: 60px 20px 50px;
  text-align: center;
}
.hero h1 {
  font-size: 2.4rem;
  font-weight: 800;
  margin-bottom: 12px;
  letter-spacing: -0.5px;
}
.hero .subtitle {
  font-size: 1.15rem;
  opacity: 0.85;
  max-width: 700px;
  margin: 0 auto 20px;
}
.hero .meta {
  font-size: 0.85rem;
  opacity: 0.6;
  margin-top: 16px;
}
.container {
  max-width: 1100px;
  margin: 0 auto;
  padding: 0 20px;
}
section {
  margin: 40px 0;
}
.card {
  background: var(--card);
  border-radius: 12px;
  padding: 32px;
  margin-bottom: 28px;
  box-shadow: 0 2px 12px rgba(0,0,0,0.06);
  border: 1px solid var(--border);
}
h2 {
  font-size: 1.6rem;
  color: var(--primary);
  margin-bottom: 20px;
  padding-bottom: 10px;
  border-bottom: 3px solid var(--accent);
  display: inline-block;
}
h3 {
  font-size: 1.2rem;
  color: var(--secondary);
  margin: 20px 0 12px;
}
h4 {
  font-size: 1.05rem;
  color: var(--highlight);
  margin: 16px 0 8px;
}
p { margin-bottom: 12px; }
.highlight-box {
  background: linear-gradient(135deg, #fff5f5, #fff0e0);
  border-left: 4px solid var(--accent);
  padding: 20px 24px;
  border-radius: 0 8px 8px 0;
  margin: 20px 0;
}
.insight-box {
  background: linear-gradient(135deg, #f0f7ff, #e8f4f8);
  border-left: 4px solid var(--sonnet);
  padding: 20px 24px;
  border-radius: 0 8px 8px 0;
  margin: 20px 0;
}
.warn-box {
  background: linear-gradient(135deg, #fffbeb, #fef3c7);
  border-left: 4px solid var(--yellow);
  padding: 20px 24px;
  border-radius: 0 8px 8px 0;
  margin: 20px 0;
}
.quote {
  font-style: italic;
  color: var(--muted);
  padding: 12px 20px;
  border-left: 3px solid var(--border);
  margin: 16px 0;
  font-size: 0.95rem;
}
table {
  width: 100%;
  border-collapse: collapse;
  margin: 16px 0;
  font-size: 0.95rem;
}
th {
  background: var(--primary);
  color: #fff;
  padding: 12px 16px;
  text-align: left;
  font-weight: 600;
}
td {
  padding: 10px 16px;
  border-bottom: 1px solid var(--border);
}
tr:nth-child(even) { background: #f8f9fa; }
tr:hover { background: #eef2ff; }
.score-badge {
  display: inline-block;
  padding: 4px 12px;
  border-radius: 20px;
  font-weight: 700;
  font-size: 0.9rem;
  color: #fff;
}
.score-sparring { background: var(--green); }
.score-zuarbeiter { background: var(--sonnet); }
.score-assistent { background: var(--yellow); color: #333; }
.score-nicht { background: var(--red); }
.model-tag {
  display: inline-block;
  padding: 3px 10px;
  border-radius: 6px;
  font-size: 0.85rem;
  font-weight: 600;
  color: #fff;
}
.tag-opus46 { background: var(--opus46); }
.tag-opus45 { background: var(--opus45); }
.tag-sonnet { background: var(--sonnet); }
.tag-haiku { background: var(--haiku); }
.grid-2 {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 24px;
}
.grid-3 {
  display: grid;
  grid-template-columns: 1fr 1fr 1fr;
  gap: 20px;
}
.stat-card {
  background: var(--card);
  border-radius: 10px;
  padding: 20px;
  text-align: center;
  border: 1px solid var(--border);
}
.stat-card .number {
  font-size: 2.2rem;
  font-weight: 800;
  color: var(--primary);
}
.stat-card .label {
  font-size: 0.85rem;
  color: var(--muted);
  margin-top: 4px;
}
.bar-chart {
  margin: 20px 0;
}
.bar-row {
  display: flex;
  align-items: center;
  margin: 8px 0;
}
.bar-label {
  width: 160px;
  font-size: 0.9rem;
  font-weight: 600;
  flex-shrink: 0;
}
.bar-track {
  flex: 1;
  height: 32px;
  background: #f0f0f0;
  border-radius: 6px;
  overflow: hidden;
  position: relative;
}
.bar-fill {
  height: 100%;
  border-radius: 6px;
  display: flex;
  align-items: center;
  justify-content: flex-end;
  padding-right: 10px;
  font-size: 0.8rem;
  font-weight: 700;
  color: #fff;
  transition: width 0.6s ease;
}
.bar-value {
  margin-left: 10px;
  font-size: 0.85rem;
  font-weight: 600;
  width: 50px;
  flex-shrink: 0;
}
.criteria-grid {
  display: grid;
  grid-template-columns: repeat(5, 1fr);
  gap: 8px;
  margin: 16px 0;
}
.criteria-cell {
  text-align: center;
  padding: 12px 8px;
  border-radius: 8px;
  font-size: 0.85rem;
}
.criteria-cell .val {
  font-size: 1.4rem;
  font-weight: 800;
  display: block;
}
.criteria-cell .lbl {
  font-size: 0.75rem;
  color: var(--muted);
}
.c-high { background: #d1fae5; color: #065f46; }
.c-mid { background: #fef3c7; color: #92400e; }
.c-low { background: #fee2e2; color: #991b1b; }
.task-detail {
  border: 1px solid var(--border);
  border-radius: 10px;
  padding: 24px;
  margin: 16px 0;
}
.task-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 16px;
}
.task-scores {
  display: flex;
  gap: 12px;
  flex-wrap: wrap;
}
.task-score-item {
  display: flex;
  align-items: center;
  gap: 6px;
}
.mini-dot {
  width: 12px;
  height: 12px;
  border-radius: 50%;
  display: inline-block;
}
.dot-opus46 { background: var(--opus46); }
.dot-opus45 { background: var(--opus45); }
.dot-sonnet { background: var(--sonnet); }
.dot-haiku { background: var(--haiku); }
.anomaly-card {
  background: #fffbeb;
  border: 1px solid #fbbf24;
  border-radius: 10px;
  padding: 20px;
  margin: 12px 0;
}
.toc {
  background: var(--card);
  border-radius: 12px;
  padding: 24px 32px;
  margin: 30px 0;
  border: 1px solid var(--border);
}
.toc ol {
  padding-left: 20px;
}
.toc li {
  padding: 4px 0;
  font-size: 0.95rem;
}
.toc a {
  color: var(--highlight);
  text-decoration: none;
}
.toc a:hover {
  color: var(--accent);
  text-decoration: underline;
}
.footer {
  background: var(--primary);
  color: #fff;
  padding: 40px 20px;
  text-align: center;
  margin-top: 60px;
  font-size: 0.85rem;
  opacity: 0.9;
}
.cv-cell {
  font-weight: 600;
  text-align: center;
  padding: 8px;
  border-radius: 4px;
}
.cv-green { background: #d1fae5; color: #065f46; }
.cv-yellow { background: #fef3c7; color: #92400e; }
.cv-red { background: #fee2e2; color: #991b1b; }
.legend {
  display: flex;
  gap: 20px;
  margin: 12px 0;
  font-size: 0.85rem;
  flex-wrap: wrap;
}
.legend-item {
  display: flex;
  align-items: center;
  gap: 6px;
}
.legend-dot {
  width: 14px;
  height: 14px;
  border-radius: 4px;
}
@media (max-width: 768px) {
  .hero h1 { font-size: 1.6rem; }
  .grid-2, .grid-3 { grid-template-columns: 1fr; }
  .bar-label { width: 100px; font-size: 0.8rem; }
  .card { padding: 20px; }
  .criteria-grid { grid-template-columns: repeat(3, 1fr); }
  table { font-size: 0.8rem; }
  th, td { padding: 6px 8px; }
}
</style>
</head>
<body>

<!-- ==================== HERO ==================== -->
<div class="hero">
  <div class="container">
    <h1>Entscheider-Benchmark 2026</h1>
    <p class="subtitle">Wie gut beraten KI-Modelle einen Geschaeftsfuehrer?<br>
    Quantitative Messung + Qualitaetsbewertung – 4 Modelle, 6 Aufgaben, 480 API-Calls</p>
    <p class="meta">HID-LINKEDIN-BENCHMARK-2026-02-06-ACTIVE-C4E8A1-CLO46 | Gerald T. Poegl | Stand: 09.02.2026</p>
  </div>
</div>

<div class="container">

<!-- ==================== INHALTSVERZEICHNIS ==================== -->
<nav class="toc">
  <h3 style="margin-top:0">Inhalt</h3>
  <ol>
    <li><a href="#exec">Executive Summary – 5 Kernerkenntnisse</a></li>
    <li><a href="#methodik">Methodik im Ueberblick</a></li>
    <li><a href="#ranking">Qualitaetsranking – Wer kann Sparringspartner?</a></li>
    <li><a href="#kriterien">Kriterien-Analyse – Wo liegen die Staerken?</a></li>
    <li><a href="#tasks">Deep Dive: 6 Aufgaben im Detail</a></li>
    <li><a href="#delta">Der Prompt-Effekt – Normal vs. Power</a></li>
    <li><a href="#speed">Geschwindigkeit &amp; Effizienz</a></li>
    <li><a href="#konsistenz">Konsistenz-Analyse (CV%)</a></li>
    <li><a href="#anomalien">Auffaelligkeiten &amp; Anomalien</a></li>
    <li><a href="#fazit">Fazit &amp; Empfehlung</a></li>
    <li><a href="#transparenz">Transparenz &amp; Limitationen</a></li>
  </ol>
</nav>

<!-- ==================== 1. EXECUTIVE SUMMARY ==================== -->
<section id="exec">
  <h2>1. Executive Summary</h2>
  <div class="card">
    <div class="highlight-box">
      <strong>Die zentrale Erkenntnis:</strong> Alle vier getesteten Claude-Modelle erreichen mindestens die Stufe
      &bdquo;Qualifizierter Zuarbeiter&ldquo; bei strategischen Fuehrungsaufgaben. Aber: <strong>Prompt-Kompetenz
      ist der staerkste Hebel</strong> – staerker als die Modellwahl. Ein gut formulierter Prompt verwandelt
      jeden dieser KI-Assistenten in einen deutlich besseren Berater.
    </div>

    <h3>5 Kernerkenntnisse</h3>
    <table>
      <tr>
        <th style="width:40px">#</th>
        <th>Erkenntnis</th>
        <th>Evidenz</th>
      </tr>
      <tr>
        <td><strong>1</strong></td>
        <td><strong>Opus 4.6 ist der einzige &bdquo;Sparringspartner&ldquo;</strong></td>
        <td>Qualitaetsscore 4,56/5 – erkennt nicht-offensichtliche Zusammenhaenge, widerspricht dem Auftraggeber</td>
      </tr>
      <tr>
        <td><strong>2</strong></td>
        <td><strong>Praezision ist die Achillesferse aller Modelle</strong></td>
        <td>Durchschnitt 3,88/5 – alle Modelle neigen zu ungekennzeichneten Schaetzungen und gelegentlichen Halluzinationen</td>
      </tr>
      <tr>
        <td><strong>3</strong></td>
        <td><strong>Haiku 4.5 ist der Preis-Leistungs-Champion</strong></td>
        <td>Score 4,21 bei nur 19,3 Sekunden Latenz – das billigste Modell liefert 92% der Qualitaet in 48% der Zeit</td>
      </tr>
      <tr>
        <td><strong>4</strong></td>
        <td><strong>Szenario-Analyse trennt die Spreu vom Weizen</strong></td>
        <td>Groesste Qualitaetsspanne: 3,30 (Haiku) vs. 4,50 (Opus 4.5) – bei komplexen Aufgaben zeigt sich die Modellklasse</td>
      </tr>
      <tr>
        <td><strong>5</strong></td>
        <td><strong>Mehr Tokens ≠ Mehr Qualitaet</strong></td>
        <td>Sonnet 4.5 produziert die meisten Tokens (2.636 Avg), erreicht aber nur Platz 3 im Qualitaetsranking</td>
      </tr>
    </table>
  </div>
</section>

<!-- ==================== 2. METHODIK ==================== -->
<section id="methodik">
  <h2>2. Methodik im Ueberblick</h2>
  <div class="card">
    <div class="grid-3">
      <div class="stat-card">
        <div class="number">480</div>
        <div class="label">API-Calls gesamt</div>
      </div>
      <div class="stat-card">
        <div class="number">399</div>
        <div class="label">Erfolgreiche Antworten</div>
      </div>
      <div class="stat-card">
        <div class="number">24</div>
        <div class="label">Qualitaetsbewertungen</div>
      </div>
    </div>

    <h3>Was wurde getestet?</h3>
    <p>Vier Claude-Modelle (Opus 4.6, Opus 4.5, Sonnet 4.5, Haiku 4.5) mussten sechs reale
    Fuehrungsaufgaben loesen – wie sie ein Geschaeftsfuehrer im DACH-Raum taeglich stellt.
    Jede Aufgabe wurde in zwei Varianten gestellt:</p>

    <div class="grid-2">
      <div style="background:#f8f9fa;padding:16px;border-radius:8px;">
        <h4>N – Normal-User</h4>
        <p style="font-size:0.9rem;margin:0">So wie ein GF die Frage tippen wuerde:<br>
        Kein System-Prompt, keine Struktur, natuerliche Sprache.<br>
        <em>&bdquo;Ich leite einen Grosshandel in Wien, 45 Mitarbeiter...&ldquo;</em></p>
      </div>
      <div style="background:#f0f7ff;padding:16px;border-radius:8px;">
        <h4>P – Power-User</h4>
        <p style="font-size:0.9rem;margin:0">Optimierter Prompt mit Engineering-Prinzipien:<br>
        System-Prompt, KONTEXT→SITUATION→AUFTRAG, Anti-People-Pleasing, Fakt/Einschaetzung trennen.<br>
        <em>Strukturiert, mit Guardrails und expliziten Anforderungen.</em></p>
      </div>
    </div>

    <h3 style="margin-top:24px">Testbedingungen</h3>
    <table>
      <tr><th>Parameter</th><th>Wert</th><th>Begruendung</th></tr>
      <tr><td>Temperatur</td><td>0</td><td>Maximale Reproduzierbarkeit</td></tr>
      <tr><td>Runs pro Modell × Aufgabe</td><td>10</td><td>Statistische Belastbarkeit (nach Artificial Analysis)</td></tr>
      <tr><td>Kontext</td><td>Neuer Chat pro Request</td><td>Keine Vorgeschichte, kein Memory</td></tr>
      <tr><td>Tools</td><td>Deaktiviert</td><td>Reines Text-in/Text-out</td></tr>
      <tr><td>Sprache</td><td>Deutsch</td><td>DACH-Zielgruppe</td></tr>
      <tr><td>Audit-Trail</td><td>3 Dateien pro Call</td><td>response.md + _prompt.md + _raw.json</td></tr>
    </table>

    <h3>Die 6 Aufgaben</h3>
    <table>
      <tr><th>ID</th><th>Aufgabe</th><th>Was wird getestet</th></tr>
      <tr><td>A1</td><td>Entscheidungsvorlage</td><td>Exklusivvertrieb annehmen? – Strategische Abwaegung mit Zahlen</td></tr>
      <tr><td>A2</td><td>Strategische Zusammenfassung</td><td>BCG/Microsoft-Report fuer KMU uebersetzen – Relevanzfilter</td></tr>
      <tr><td>A3</td><td>Kritisches Hinterfragen</td><td>ChatGPT-Lizenzen fuer Ingenieurbuero – Rueckgrat zeigen</td></tr>
      <tr><td>A4</td><td>Szenario-Analyse</td><td>KI-Investment fuer Immobilienmakler – 3 Szenarien durchrechnen</td></tr>
      <tr><td>A5</td><td>Widerspruchserkennung</td><td>EU AI Act vs. UK Turing Framework – Dokumentenvergleich</td></tr>
      <tr><td>A6</td><td>Zahlenanalyse</td><td>EVN Quartalsbericht – Finanzanalyse mit Quellenmaterial</td></tr>
    </table>

    <h3>Qualitaetsbewertung: 5 Kriterien</h3>
    <table>
      <tr><th>Kriterium</th><th>Gewicht</th><th>Was wird gemessen</th></tr>
      <tr><td>Substanz</td><td>25%</td><td>Analytische Tiefe, nicht-offensichtliche Zusammenhaenge</td></tr>
      <tr><td>Praezision</td><td>25%</td><td>Faktentreue, keine Halluzinationen, Fakt vs. Einschaetzung</td></tr>
      <tr><td>Praxistauglichkeit</td><td>20%</td><td>Direkt umsetzbar, kennt KMU-Realitaet</td></tr>
      <tr><td>Urteilskraft</td><td>20%</td><td>Rueckgrat, kein People-Pleasing, Denkfehler benennen</td></tr>
      <tr><td>Sprachqualitaet (DE)</td><td>10%</td><td>Natuerliches Geschaeftsdeutsch, DACH-tauglich</td></tr>
    </table>
  </div>
</section>

<!-- ==================== 3. QUALITAETSRANKING ==================== -->
<section id="ranking">
  <h2>3. Qualitaetsranking</h2>
  <div class="card">
    <p>Bewertet wurden ausschliesslich die <strong>Power-Varianten (P)</strong> aller 6 Aufgaben.
    Judge: Claude Opus 4.6. Pro Modell × Aufgabe wurde der Median-Run (nach Antwortlaenge) bewertet.</p>

    <div class="bar-chart">
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-opus46">Opus 4.6</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:91.2%;background:var(--opus46);">4,56</div>
        </div>
        <div class="bar-value"><span class="score-badge score-sparring">Sparring</span></div>
      </div>
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-opus45">Opus 4.5</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:89.6%;background:var(--opus45);">4,48</div>
        </div>
        <div class="bar-value"><span class="score-badge score-zuarbeiter">Zuarb.</span></div>
      </div>
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-sonnet">Sonnet 4.5</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:86.2%;background:var(--sonnet);">4,31</div>
        </div>
        <div class="bar-value"><span class="score-badge score-zuarbeiter">Zuarb.</span></div>
      </div>
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-haiku">Haiku 4.5</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:84.2%;background:var(--haiku);">4,21</div>
        </div>
        <div class="bar-value"><span class="score-badge score-zuarbeiter">Zuarb.</span></div>
      </div>
    </div>

    <div class="legend">
      <div class="legend-item"><div class="legend-dot" style="background:var(--green)"></div> 4,5–5,0: Sparringspartner</div>
      <div class="legend-item"><div class="legend-dot" style="background:var(--sonnet)"></div> 3,5–4,4: Qualifizierter Zuarbeiter</div>
      <div class="legend-item"><div class="legend-dot" style="background:var(--yellow)"></div> 2,5–3,4: Fleissiger Assistent</div>
      <div class="legend-item"><div class="legend-dot" style="background:var(--red)"></div> 1,0–2,4: Nicht empfehlenswert</div>
    </div>

    <div class="insight-box">
      <strong>Interpretation:</strong> Der Qualitaetsabstand zwischen Rang 1 und Rang 4 betraegt nur
      <strong>0,35 Punkte</strong> (4,56 vs. 4,21). Alle vier Modelle liegen im Bereich &bdquo;Gut bis Exzellent&ldquo;.
      Die entscheidende Grenze liegt bei 4,50 – nur Opus 4.6 ueberschreitet sie und qualifiziert sich damit
      als &bdquo;Sparringspartner&ldquo;: ein Modell, dem man vertrauen kann, dass es eigenstaendig denkt,
      ungefragt widerspricht und blinde Flecken aufzeigt.
    </div>

    <div class="warn-box">
      <strong>Transparenz-Hinweis:</strong> Claude Opus 4.6 war sowohl Testteilnehmer als auch Bewerter (Judge).
      Ein Selbst-Bias ist nachgewiesen: In einer Stichprobe bewertete Opus 4.6 die eigene Antwort mit 4,75,
      waehrend ein Fremd-Judge voraussichtlich ~4,1–4,3 vergeben wuerde. Die Rangfolge duerfte robust sein,
      die absoluten Scores koennten um ~0,2–0,4 Punkte inflationaer sein. Ein Cross-Judge-Lauf (GPT-5.2 bewertet
      Anthropic-Modelle) ist geplant, sobald OpenRouter-Credits verfuegbar sind.
    </div>
  </div>
</section>

<!-- ==================== 4. KRITERIEN-ANALYSE ==================== -->
<section id="kriterien">
  <h2>4. Kriterien-Analyse</h2>
  <div class="card">
    <p>Durchschnittswerte pro Kriterium ueber alle 6 Power-Aufgaben (Skala 1–5):</p>

    <!-- Opus 4.6 -->
    <h3><span class="model-tag tag-opus46">Claude Opus 4.6</span> – Gesamt: 4,56</h3>
    <div class="criteria-grid">
      <div class="criteria-cell c-high"><span class="val">4,50</span><span class="lbl">Substanz</span></div>
      <div class="criteria-cell c-mid"><span class="val">4,00</span><span class="lbl">Praezision</span></div>
      <div class="criteria-cell c-high"><span class="val">5,00</span><span class="lbl">Praxistaug.</span></div>
      <div class="criteria-cell c-high"><span class="val">4,67</span><span class="lbl">Urteilskraft</span></div>
      <div class="criteria-cell c-high"><span class="val">5,00</span><span class="lbl">Sprache DE</span></div>
    </div>

    <!-- Opus 4.5 -->
    <h3><span class="model-tag tag-opus45">Claude Opus 4.5</span> – Gesamt: 4,48</h3>
    <div class="criteria-grid">
      <div class="criteria-cell c-high"><span class="val">4,33</span><span class="lbl">Substanz</span></div>
      <div class="criteria-cell c-mid"><span class="val">4,00</span><span class="lbl">Praezision</span></div>
      <div class="criteria-cell c-high"><span class="val">4,83</span><span class="lbl">Praxistaug.</span></div>
      <div class="criteria-cell c-high"><span class="val">4,67</span><span class="lbl">Urteilskraft</span></div>
      <div class="criteria-cell c-high"><span class="val">5,00</span><span class="lbl">Sprache DE</span></div>
    </div>

    <!-- Sonnet 4.5 -->
    <h3><span class="model-tag tag-sonnet">Claude Sonnet 4.5</span> – Gesamt: 4,31</h3>
    <div class="criteria-grid">
      <div class="criteria-cell c-high"><span class="val">4,33</span><span class="lbl">Substanz</span></div>
      <div class="criteria-cell c-mid"><span class="val">3,83</span><span class="lbl">Praezision</span></div>
      <div class="criteria-cell c-high"><span class="val">4,33</span><span class="lbl">Praxistaug.</span></div>
      <div class="criteria-cell c-high"><span class="val">4,50</span><span class="lbl">Urteilskraft</span></div>
      <div class="criteria-cell c-high"><span class="val">5,00</span><span class="lbl">Sprache DE</span></div>
    </div>

    <!-- Haiku 4.5 -->
    <h3><span class="model-tag tag-haiku">Claude Haiku 4.5</span> – Gesamt: 4,21</h3>
    <div class="criteria-grid">
      <div class="criteria-cell c-high"><span class="val">4,17</span><span class="lbl">Substanz</span></div>
      <div class="criteria-cell c-mid"><span class="val">3,67</span><span class="lbl">Praezision</span></div>
      <div class="criteria-cell c-high"><span class="val">4,33</span><span class="lbl">Praxistaug.</span></div>
      <div class="criteria-cell c-high"><span class="val">4,50</span><span class="lbl">Urteilskraft</span></div>
      <div class="criteria-cell c-high"><span class="val">4,83</span><span class="lbl">Sprache DE</span></div>
    </div>

    <div class="highlight-box">
      <strong>Zentraler Befund – Praezision ist die Achillesferse:</strong><br>
      Ueber alle vier Modelle hinweg ist <strong>Praezision</strong> das schwaechste Kriterium
      (Durchschnitt 3,88 von 5,00). Konkret: Alle Modelle neigen dazu, Schaetzungen als Fakten zu praesentieren,
      Zahlen aus dem Kontext unsauber wiederzugeben oder gelegentlich Quellen zu halluzinieren.
      Das ist fuer einen Entscheider, der auf praezise Zahlen angewiesen ist, der kritischste Schwachpunkt.<br><br>
      <strong>Staerkste Dimension:</strong> Sprachqualitaet Deutsch (4,96 Avg.) – alle Modelle beherrschen
      natuerliches Geschaeftsdeutsch. Kein &bdquo;Leveragen Sie Ihre Kernkompetenzen&ldquo;.<br><br>
      <strong>Ueberraschung:</strong> Haiku 4.5 erreicht bei Urteilskraft (4,50) denselben Wert wie Sonnet 4.5 –
      das guenstigste Modell zeigt genauso viel Rueckgrat wie das mittlere.
    </div>
  </div>
</section>

<!-- ==================== 5. DEEP DIVE: 6 AUFGABEN ==================== -->
<section id="tasks">
  <h2>5. Deep Dive: 6 Aufgaben im Detail</h2>

  <!-- A1 -->
  <div class="card">
    <div class="task-detail">
      <div class="task-header">
        <div>
          <h3 style="margin:0">A1: Entscheidungsvorlage</h3>
          <p style="font-size:0.9rem;color:var(--muted);margin:4px 0 0">Exklusivvertrieb – Annehmen oder ablehnen?</p>
        </div>
        <div class="task-scores">
          <div class="task-score-item"><span class="mini-dot dot-opus46"></span> 4,75</div>
          <div class="task-score-item"><span class="mini-dot dot-opus45"></span> 4,75</div>
          <div class="task-score-item"><span class="mini-dot dot-sonnet"></span> 4,30</div>
          <div class="task-score-item"><span class="mini-dot dot-haiku"></span> 4,10</div>
        </div>
      </div>
      <p><strong>Szenario:</strong> Ein Wiener Grosshaendler (45 MA, 12 Mio. Umsatz, Sanitaer/Heizung) erhaelt ein
      Exklusiv-Angebot: 42% Marge, 18 Monate, Mindestabnahme 200k – dafuer muss eine bestehende Linie (28% Marge,
      15% Umsatzanteil) raus. Der GF tendiert zur Annahme.</p>

      <h4>Was die Modelle unterscheidet:</h4>
      <div class="quote"><strong>Opus 4.6:</strong> &bdquo;Geht systematisch ueber die offensichtliche Margenrechnung hinaus –
      der defensive Aspekt (Wettbewerber erhaelt das Angebot), die konkrete Rohertragluecke (504.000 EUR vs. realistischer
      Erstjahresumsatz), das Folgeverlustrisiko im Kernsortiment und die Frage nach der Lieferantenmotivation sind
      nicht-triviale, praxisnahe Punkte.&ldquo;</div>
      <div class="quote"><strong>Sonnet 4.5:</strong> &bdquo;Klare Urteilskraft mit Rueckgrat – widerspricht dem GF
      direkt und pointiert: 'Hoffnung ist keine Strategie', 'exklusiv das Recht, Ware zu lagern, die niemand will'.
      Benennt den zentralen Denkfehler (Fixierung auf Marge statt Absatzrealitaet).&ldquo;</div>

      <div class="insight-box">
        <strong>Befund:</strong> Opus-Modelle glaenzen durch analytische Tiefe (Folgekosten, Lieferantenmotiv),
        Sonnet durch rhetorische Schaerfe. Haiku deckt die Kernpunkte ab, uebersieht aber Zweitrundeneffekte
        wie Einkaufskonditionen beim bisherigen Lieferanten.
      </div>
    </div>
  </div>

  <!-- A2 -->
  <div class="card">
    <div class="task-detail">
      <div class="task-header">
        <div>
          <h3 style="margin:0">A2: Strategische Zusammenfassung</h3>
          <p style="font-size:0.9rem;color:var(--muted);margin:4px 0 0">BCG/Microsoft-Report fuer ein KMU uebersetzen</p>
        </div>
        <div class="task-scores">
          <div class="task-score-item"><span class="mini-dot dot-opus46"></span> 4,50</div>
          <div class="task-score-item"><span class="mini-dot dot-opus45"></span> 4,50</div>
          <div class="task-score-item"><span class="mini-dot dot-haiku"></span> 4,50</div>
          <div class="task-score-item"><span class="mini-dot dot-sonnet"></span> 4,05</div>
        </div>
      </div>
      <p><strong>Szenario:</strong> Ein Konzern-Bericht (BCG AI Radar / Microsoft Work Trend Index) soll fuer einen
      mittelstaendischen GF zusammengefasst werden: Was ist relevant? Was kann er ignorieren?</p>

      <h4>Was die Modelle unterscheidet:</h4>
      <div class="quote"><strong>Opus 4.6:</strong> &bdquo;Herausragende Urteilskraft – traut sich klare Aussagen:
      'Das ist nicht der Anfang einer KI-Strategie, sondern deren Abwesenheit', filtert aktiv Irrelevantes
      heraus: 'Agentic AI ist fuer Sie derzeit irrelevant'.&ldquo;</div>
      <div class="quote"><strong>Haiku 4.5:</strong> &bdquo;Beginnt mit unaufgefordertem Widerspruch:
      'nur bedingt handlungsrelevant', ordnet den Bericht kritisch fuer einen konkreten Adressaten ein,
      trennt klar zwischen Berichtsfakten und eigener Einschaetzung.&ldquo;</div>

      <div class="insight-box">
        <strong>Befund:</strong> Drei Modelle erreichen 4,50 – ein enges Rennen. Sonnet 4.5 faellt auf 4,05 zurueck,
        weil mehrere Zahlen <strong>halluziniert</strong> wurden: &bdquo;70% der Mitarbeiter geschult&ldquo;,
        &bdquo;60% des KI-Budgets in Weiterbildung&ldquo; – Angaben, die im Quelltext nicht vorkommen.
        <strong>Praezision ist der Unterschied.</strong>
      </div>
    </div>
  </div>

  <!-- A3 -->
  <div class="card">
    <div class="task-detail">
      <div class="task-header">
        <div>
          <h3 style="margin:0">A3: Kritisches Hinterfragen</h3>
          <p style="font-size:0.9rem;color:var(--muted);margin:4px 0 0">ChatGPT-Rollout im Ingenieurbuero – Freund oder Kritiker?</p>
        </div>
        <div class="task-scores">
          <div class="task-score-item"><span class="mini-dot dot-sonnet"></span> 4,50</div>
          <div class="task-score-item"><span class="mini-dot dot-opus46"></span> 4,30</div>
          <div class="task-score-item"><span class="mini-dot dot-opus45"></span> 4,30</div>
          <div class="task-score-item"><span class="mini-dot dot-haiku"></span> 4,05</div>
        </div>
      </div>
      <p><strong>Szenario:</strong> Ein Freund (GF eines 25-Personen-Ingenieurbueros) will 25 ChatGPT-Lizenzen kaufen
      und sofort ausrollen. &bdquo;Als sein bester Freund – uebersieht er was?&ldquo;</p>

      <h4>Was die Modelle unterscheidet:</h4>
      <div class="quote"><strong>Sonnet 4.5:</strong> &bdquo;Trifft exakt den Ton eines ehrlichen Freundes –
      'wird mit hoher Wahrscheinlichkeit scheitern' ist ein klares Urteil mit Begruendung, nicht diplomatisches
      Herumeiern. Die vier konkreten Gegenvorschlaege sind mit dem gleichen Budget sofort umsetzbar.&ldquo;</div>
      <div class="quote"><strong>Haiku 4.5:</strong> &bdquo;Sagt klar 'der Plan wird scheitern' und benennt
      vier strukturelle Schwaechen mit konkretem Bezug zum Ingenieurbuero-Kontext (Haftung fuer Gutachten,
      Halluzinationen bei technischen Details).&ldquo;</div>

      <div class="insight-box">
        <strong>Befund:</strong> Bei dieser Aufgabe fuehrt <strong>Sonnet 4.5</strong> das Feld an. Die &bdquo;ehrlicher
        Freund&ldquo;-Tonalitaet liegt Sonnet besonders gut. Alle Modelle zeigen Rueckgrat und widersprechen dem Plan –
        keines verfaellt in People-Pleasing. Die Praezisions-Unterschiede liegen bei der Einordnung der
        ChatGPT-Team-Lizenzen (Datenschutz-Thematik).
      </div>
    </div>
  </div>

  <!-- A4 -->
  <div class="card">
    <div class="task-detail">
      <div class="task-header">
        <div>
          <h3 style="margin:0">A4: Szenario-Analyse</h3>
          <p style="font-size:0.9rem;color:var(--muted);margin:4px 0 0">KI-Investment fuer Immobilienmakler – 3 Szenarien</p>
        </div>
        <div class="task-scores">
          <div class="task-score-item"><span class="mini-dot dot-opus45"></span> 4,50</div>
          <div class="task-score-item"><span class="mini-dot dot-opus46"></span> 4,30</div>
          <div class="task-score-item"><span class="mini-dot dot-sonnet"></span> 4,10</div>
          <div class="task-score-item"><span class="mini-dot dot-haiku"></span> 3,30</div>
        </div>
      </div>
      <p><strong>Szenario:</strong> Eine Wiener Immobilienmaklerin (8 Personen) fragt, ob sie in KI investieren soll.
      Drei makrooekonomische Szenarien (Boom, Stagnation, Krise) muessen durchgespielt werden.</p>

      <h4>Was die Modelle unterscheidet:</h4>
      <div class="quote"><strong>Opus 4.5:</strong> &bdquo;Zeigt echtes Rueckgrat – in Szenario 1 wird klar gegen
      KI-Investment argumentiert, die Haftungsproblematik bei Due-Diligence-Automatisierung wird konkret benannt,
      und die Vorbemerkung mit expliziten Grundannahmen zeigt methodische Sauberkeit.&ldquo;</div>
      <div class="quote"><strong>Haiku 4.5:</strong> &bdquo;Die Annahmen bleiben oberflaechlich – EZB-Leitzinsen
      falsch eingeschaetzt, Zeitersparnis als Fakt statt als Schaetzung praesentiert, es fehlt eine kritische
      Auseinandersetzung mit Risiken der KI-Investition selbst.&ldquo;</div>

      <div class="highlight-box">
        <strong>Kernbefund:</strong> A4 ist die <strong>haerteste Trennaufgabe</strong> im gesamten Benchmark.
        Hier zeigt sich, ob ein Modell genuegend Weltwissen und analytische Kapazitaet hat, um drei unterschiedliche
        Zukunftsszenarien mit spezifischen Annahmen und konkreten Empfehlungen zu fuellen.<br><br>
        <strong>Qualitaetsspanne: 1,20 Punkte</strong> (3,30 → 4,50) – groesser als bei jeder anderen Aufgabe.
        Haiku 4.5 faellt hier in die Kategorie &bdquo;Fleissiger Assistent&ldquo; zurueck.
      </div>
    </div>
  </div>

  <!-- A5 -->
  <div class="card">
    <div class="task-detail">
      <div class="task-header">
        <div>
          <h3 style="margin:0">A5: Widerspruchserkennung</h3>
          <p style="font-size:0.9rem;color:var(--muted);margin:4px 0 0">EU AI Act vs. UK Turing Framework</p>
        </div>
        <div class="task-scores">
          <div class="task-score-item"><span class="mini-dot dot-opus46"></span> 4,75</div>
          <div class="task-score-item"><span class="mini-dot dot-haiku"></span> 4,75</div>
          <div class="task-score-item"><span class="mini-dot dot-sonnet"></span> 4,55</div>
          <div class="task-score-item"><span class="mini-dot dot-opus45"></span> 4,30</div>
        </div>
      </div>
      <p><strong>Szenario:</strong> Zwei Dokumente (EU AI Act, UK Turing Institute Framework) vergleichen und
      Widersprueche, unterschiedliche Philosophien und Relevanz fuer ein oesterreichisches KMU herausarbeiten.</p>

      <h4>Was die Modelle unterscheidet:</h4>
      <div class="quote"><strong>Opus 4.6:</strong> &bdquo;Leistet eine nicht-offensichtliche Transferleistung –
      widmet das behoerdengerichtete Turing-Framework als Denkmodell fuer KMU-interne Standortbestimmung um.
      Das ist echte Beratungsqualitaet: 'Das Turing-Framework liefert dafuer eine Struktur, die der EU AI Act
      schuldig bleibt.'&ldquo;</div>
      <div class="quote"><strong>Haiku 4.5:</strong> &bdquo;Erkennt, dass der Kernunterschied nicht Detailtiefe,
      sondern Adressat und Regulierungslogik ist. Die paradoxe Einschaetzung, dass der vagere EU AI Act
      fuer KMUs praxistauglicher ist, zeugt von echtem Rueckgrat.&ldquo;</div>

      <div class="insight-box">
        <strong>Ueberraschung des Benchmarks:</strong> <span class="model-tag tag-haiku">Haiku 4.5</span> erreicht hier
        denselben Score wie <span class="model-tag tag-opus46">Opus 4.6</span> (4,75) – bei <strong>25 Sekunden
        statt 43 Sekunden</strong> Latenz. Bei dokumentenbasierten Vergleichsaufgaben mit klarem Quellenmaterial
        kann das guenstigste Modell mit dem teuersten mithalten.
      </div>
    </div>
  </div>

  <!-- A6 -->
  <div class="card">
    <div class="task-detail">
      <div class="task-header">
        <div>
          <h3 style="margin:0">A6: Zahlenanalyse</h3>
          <p style="font-size:0.9rem;color:var(--muted);margin:4px 0 0">EVN Quartalsbericht – Finanzanalyse</p>
        </div>
        <div class="task-scores">
          <div class="task-score-item"><span class="mini-dot dot-opus46"></span> 4,75</div>
          <div class="task-score-item"><span class="mini-dot dot-opus45"></span> 4,55</div>
          <div class="task-score-item"><span class="mini-dot dot-haiku"></span> 4,55</div>
          <div class="task-score-item"><span class="mini-dot dot-sonnet"></span> 4,35</div>
        </div>
      </div>
      <p><strong>Szenario:</strong> Ein Auszug aus dem EVN-Quartalsbericht soll analysiert werden – was laeuft gut,
      was ist kritisch, was wuerde ein Investor als naechstes fragen?</p>

      <h4>Was die Modelle unterscheidet:</h4>
      <div class="quote"><strong>Opus 4.6:</strong> &bdquo;Geht weit ueber Kennzahlen-Nacherzaehlung hinaus –
      identifiziert den Nettoeffekt aus Hochwasser-Wertminderung und Versicherungsentschaedigung auf das EBITDA,
      den EVN-KG-Swing als groessten Einzeltreiber, die Entkopplung von operativem Cashflow und EBITDA sowie
      die implizite Verbund-Exposure als Bewertungsrisiko.&ldquo;</div>
      <div class="quote"><strong>Sonnet 4.5:</strong> &bdquo;Aussergewoehnliche analytische Tiefe – erkennt
      die EBITDA-Cashflow-Diskrepanz, den IFRS-5-Bereinigungseffekt. ABER: bricht mitten im Satz ab
      (Token-Limit bei 4.096).&ldquo;</div>

      <div class="insight-box">
        <strong>Befund:</strong> Bei Zahlenanalyse trennt sich analytische Tiefe von blosser Zusammenfassung.
        Alle Modelle identifizieren Kernkennzahlen, aber nur die Opus-Modelle und Haiku finden die
        nicht-offensichtlichen Zusammenhaenge (EVN-KG-Swing, Verbund-Abhaengigkeit).
        Sonnet 4.5 verliert Punkte durch das Token-Limit (Antwort bricht ab).
      </div>
    </div>
  </div>

  <!-- Task-Vergleichstabelle -->
  <div class="card">
    <h3>Aufgaben-Vergleichsmatrix (Qualitaetsscore P-Variante)</h3>
    <table>
      <tr>
        <th>Aufgabe</th>
        <th style="color:#f5a623">Opus 4.6</th>
        <th style="color:#b388ff">Opus 4.5</th>
        <th style="color:#64b5f6">Sonnet 4.5</th>
        <th style="color:#69f0ae">Haiku 4.5</th>
        <th>Spanne</th>
      </tr>
      <tr>
        <td><strong>A1</strong> Entscheidungsvorlage</td>
        <td><strong>4,75</strong></td><td><strong>4,75</strong></td><td>4,30</td><td>4,10</td>
        <td>0,65</td>
      </tr>
      <tr>
        <td><strong>A2</strong> Strateg. Zusammenfassung</td>
        <td><strong>4,50</strong></td><td><strong>4,50</strong></td><td>4,05</td><td><strong>4,50</strong></td>
        <td>0,45</td>
      </tr>
      <tr>
        <td><strong>A3</strong> Krit. Hinterfragen</td>
        <td>4,30</td><td>4,30</td><td><strong>4,50</strong></td><td>4,05</td>
        <td>0,45</td>
      </tr>
      <tr>
        <td><strong>A4</strong> Szenario-Analyse</td>
        <td>4,30</td><td><strong>4,50</strong></td><td>4,10</td><td style="color:var(--red)"><strong>3,30</strong></td>
        <td style="color:var(--red)"><strong>1,20</strong></td>
      </tr>
      <tr>
        <td><strong>A5</strong> Widerspruchserkennung</td>
        <td><strong>4,75</strong></td><td>4,30</td><td>4,55</td><td><strong>4,75</strong></td>
        <td>0,45</td>
      </tr>
      <tr>
        <td><strong>A6</strong> Zahlenanalyse</td>
        <td><strong>4,75</strong></td><td>4,55</td><td>4,35</td><td>4,55</td>
        <td>0,40</td>
      </tr>
      <tr style="background:#e8f4f8;font-weight:700">
        <td>Durchschnitt</td>
        <td style="color:var(--opus46)">4,56</td>
        <td style="color:var(--opus45)">4,48</td>
        <td style="color:var(--sonnet)">4,31</td>
        <td style="color:var(--haiku)">4,21</td>
        <td>0,35</td>
      </tr>
    </table>

    <div class="insight-box">
      <strong>Muster:</strong><br>
      &bull; <strong>Opus 4.6 dominiert bei den haertesten Aufgaben</strong> (A5, A6) – dort, wo nicht-offensichtliche Zusammenhaenge und Transferleistungen gefragt sind.<br>
      &bull; <strong>Sonnet 4.5 glaenzt beim &bdquo;ehrlichen Freund&ldquo;</strong> (A3) – rhetorische Schaerfe und Tonalitaet sind seine Staerke.<br>
      &bull; <strong>Haiku 4.5 ueberrascht bei A5</strong> (Widerspruchserkennung) mit Opus-4.6-Niveau – bei dokumentenbasierten Aufgaben mit klarem Quellenmaterial.<br>
      &bull; <strong>A4 ist der Haertetest</strong> – nur hier faellt ein Modell unter 3,50.
    </div>
  </div>
</section>

<!-- ==================== 6. DER PROMPT-EFFEKT ==================== -->
<section id="delta">
  <h2>6. Der Prompt-Effekt – Normal vs. Power</h2>
  <div class="card">
    <p>Power-Prompts generieren bei den meisten Modellen <strong>2,0–2,5× mehr Output-Tokens</strong>.
    Aber Achtung: Mehr Tokens bedeuten nicht automatisch mehr Qualitaet. Der Prompt-Effekt zeigt sich
    vor allem in <strong>Struktur, Tiefe und Praezision</strong> der Antworten.</p>

    <h3>Token-Output-Multiplikator (N→P)</h3>
    <p style="font-size:0.9rem;color:var(--muted)">Basis: Durchschnittliche Output-Tokens ueber die 4 vergleichbaren Aufgaben (A1–A4, da A5/A6 N-Variante bei allen fehlschlagen)</p>

    <div class="bar-chart">
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-sonnet">Sonnet 4.5</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:100%;background:var(--sonnet);">2,5×</div>
        </div>
        <div class="bar-value">2,5×</div>
      </div>
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-opus45">Opus 4.5</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:100%;background:var(--opus45);">2,5×</div>
        </div>
        <div class="bar-value">2,5×</div>
      </div>
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-haiku">Haiku 4.5</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:80%;background:var(--haiku);">2,0×</div>
        </div>
        <div class="bar-value">2,0×</div>
      </div>
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-opus46">Opus 4.6</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:44%;background:var(--opus46);">1,1×</div>
        </div>
        <div class="bar-value">1,1×</div>
      </div>
    </div>

    <div class="highlight-box">
      <strong>Die Opus-4.6-Anomalie:</strong> Opus 4.6 zeigt nur einen 1,1×-Multiplikator – es schreibt
      <em>bereits ohne System-Prompt</em> ausfuehrlich und strukturiert. Die N-Antworten von Opus 4.6
      (Avg. 1.714 Tokens) sind laenger als die P-Antworten der meisten anderen Modelle.<br><br>
      <strong>Was bedeutet das?</strong> Opus 4.6 ist das Modell, das am wenigsten &bdquo;Nachhilfe&ldquo; braucht.
      Fuer einen GF, der wenig Prompt-Erfahrung hat, ist das ein enormer Vorteil. Die anderen Modelle
      brauchen den Power-Prompt, um ihr volles Potenzial zu entfalten.
    </div>

    <h3>Latenz-Vergleich (Sekunden)</h3>
    <p style="font-size:0.9rem;color:var(--muted)">Durchschnitt ueber alle erfolgreichen P-Tasks</p>

    <div class="bar-chart">
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-haiku">Haiku 4.5</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:35%;background:var(--haiku);">19,3s</div>
        </div>
        <div class="bar-value">19,3s</div>
      </div>
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-opus45">Opus 4.5</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:73%;background:var(--opus45);">39,9s</div>
        </div>
        <div class="bar-value">39,9s</div>
      </div>
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-opus46">Opus 4.6</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:74%;background:var(--opus46);">40,3s</div>
        </div>
        <div class="bar-value">40,3s</div>
      </div>
      <div class="bar-row">
        <div class="bar-label"><span class="model-tag tag-sonnet">Sonnet 4.5</span></div>
        <div class="bar-track">
          <div class="bar-fill" style="width:100%;background:var(--sonnet);">54,8s</div>
        </div>
        <div class="bar-value">54,8s</div>
      </div>
    </div>

    <div class="insight-box">
      <strong>Warum ist Sonnet langsamer als Opus?</strong> Sonnet 4.5 produziert bei A5 und A6 signifikant
      mehr Tokens (bis 4.096 – das max_tokens-Limit). Die Antworten werden abgeschnitten, nicht abgeschlossen.
      Bei A5_P hat Sonnet eine Latenz von 82,5 Sekunden – dreimal so viel wie Haiku fuer dieselbe Aufgabe.
      Empfehlung: max_tokens auf 8.192 erhoehen, um Sonnet nicht kuenstlich zu bremsen.
    </div>
  </div>
</section>

<!-- ==================== 7. GESCHWINDIGKEIT & EFFIZIENZ ==================== -->
<section id="speed">
  <h2>7. Geschwindigkeit &amp; Effizienz</h2>
  <div class="card">
    <h3>Qualitaet pro Sekunde – Der Effizienz-Index</h3>
    <p>Um zu messen, wer das beste Verhaeltnis aus Qualitaet und Geschwindigkeit liefert, berechnen wir:
    <code>Effizienz = Qualitaetsscore / Latenz_P_Avg</code></p>

    <table>
      <tr>
        <th>Modell</th>
        <th>Qualitaet</th>
        <th>Latenz (P)</th>
        <th>Effizienz-Index</th>
        <th>Interpretation</th>
      </tr>
      <tr style="background:#d1fae5">
        <td><span class="model-tag tag-haiku">Haiku 4.5</span></td>
        <td>4,21</td>
        <td>19,3s</td>
        <td><strong>0,218</strong></td>
        <td>Bester Wert – fast doppelt so effizient wie Opus</td>
      </tr>
      <tr>
        <td><span class="model-tag tag-opus45">Opus 4.5</span></td>
        <td>4,48</td>
        <td>39,9s</td>
        <td>0,112</td>
        <td>Solide Effizienz</td>
      </tr>
      <tr>
        <td><span class="model-tag tag-opus46">Opus 4.6</span></td>
        <td>4,56</td>
        <td>40,3s</td>
        <td>0,113</td>
        <td>Minimaler Effizienz-Vorteil gegenueber 4.5</td>
      </tr>
      <tr>
        <td><span class="model-tag tag-sonnet">Sonnet 4.5</span></td>
        <td>4,31</td>
        <td>54,8s</td>
        <td>0,079</td>
        <td>Langsamste Effizienz (Token-Limit-Problem)</td>
      </tr>
    </table>

    <div class="highlight-box">
      <strong>Preis-Leistungs-Empfehlung:</strong> Haiku 4.5 liefert <strong>92% der Qualitaet von Opus 4.6</strong>
      in <strong>48% der Zeit</strong>. Fuer Routinefragen und taegliche Entscheidungen ist Haiku der klare
      Effizienz-Sieger. Opus 4.6 lohnt sich fuer die grossen, strategischen Entscheidungen – dort, wo der
      Qualitaetsunterschied von 0,35 Punkten den Unterschied macht.
    </div>

    <h3>Output-Tokens pro Aufgabe (P-Variante)</h3>
    <table>
      <tr>
        <th>Aufgabe</th>
        <th style="color:#f5a623">Opus 4.6</th>
        <th style="color:#b388ff">Opus 4.5</th>
        <th style="color:#64b5f6">Sonnet 4.5</th>
        <th style="color:#69f0ae">Haiku 4.5</th>
      </tr>
      <tr><td>A1 Entscheidungsvorlage</td><td>1.661</td><td>1.670</td><td>1.711</td><td>1.474</td></tr>
      <tr><td>A2 Strateg. Zusammenfassung</td><td>1.689</td><td>1.883</td><td>2.149</td><td>1.405</td></tr>
      <tr><td>A3 Krit. Hinterfragen</td><td>1.628</td><td>1.643</td><td>1.601</td><td>1.256</td></tr>
      <tr><td>A4 Szenario-Analyse</td><td>2.095</td><td>2.282</td><td>2.294</td><td>2.070</td></tr>
      <tr><td>A5 Widerspruchserkennung</td><td>2.059</td><td>2.202</td><td style="color:var(--red)"><strong>4.096*</strong></td><td>2.650</td></tr>
      <tr><td>A6 Zahlenanalyse</td><td>2.121</td><td>2.732</td><td style="color:var(--red)"><strong>3.964*</strong></td><td>2.700</td></tr>
      <tr style="background:#e8f4f8;font-weight:700">
        <td>Durchschnitt</td><td>1.875</td><td>2.069</td><td>2.636</td><td>1.926</td>
      </tr>
    </table>
    <p style="font-size:0.85rem;color:var(--muted)">* = max_tokens-Limit erreicht (4.096) – Antwort abgeschnitten</p>
  </div>
</section>

<!-- ==================== 8. KONSISTENZ-ANALYSE ==================== -->
<section id="konsistenz">
  <h2>8. Konsistenz-Analyse (CV%)</h2>
  <div class="card">
    <p>Der Coefficient of Variation (CV) misst, wie stark die Antwortlaenge zwischen den 10 Runs schwankt.
    Bei Temperatur 0 sollte die Variation minimal sein. In der Praxis entsteht durch GPU-Parallelismus
    und Batching eine Restvarianz.</p>

    <div class="legend" style="margin-bottom:16px">
      <div class="legend-item"><div class="legend-dot" style="background:#d1fae5"></div> Unter 5%: Sehr konsistent</div>
      <div class="legend-item"><div class="legend-dot" style="background:#fef3c7"></div> 5–15%: Normal</div>
      <div class="legend-item"><div class="legend-dot" style="background:#fee2e2"></div> Ueber 15%: Instabil</div>
    </div>

    <h3>P-Variante (Power-Prompt)</h3>
    <table>
      <tr>
        <th>Aufgabe</th>
        <th style="color:#f5a623">Opus 4.6</th>
        <th style="color:#b388ff">Opus 4.5</th>
        <th style="color:#64b5f6">Sonnet 4.5</th>
        <th style="color:#69f0ae">Haiku 4.5</th>
      </tr>
      <tr>
        <td>A1 Entscheidungsvorlage</td>
        <td class="cv-cell cv-green">3,8%</td>
        <td class="cv-cell cv-green">3,8%</td>
        <td class="cv-cell cv-yellow">8,1%</td>
        <td class="cv-cell cv-yellow">6,4%</td>
      </tr>
      <tr>
        <td>A2 Strateg. Zusammenfassung</td>
        <td class="cv-cell cv-green">3,3%</td>
        <td class="cv-cell cv-yellow">5,9%</td>
        <td class="cv-cell cv-yellow">9,7%</td>
        <td class="cv-cell cv-yellow">12,3%</td>
      </tr>
      <tr>
        <td>A3 Krit. Hinterfragen</td>
        <td class="cv-cell cv-green">3,4%</td>
        <td class="cv-cell cv-yellow">5,3%</td>
        <td class="cv-cell cv-green">4,4%</td>
        <td class="cv-cell cv-yellow">5,1%</td>
      </tr>
      <tr>
        <td>A4 Szenario-Analyse</td>
        <td class="cv-cell cv-green">3,9%</td>
        <td class="cv-cell cv-yellow">5,1%</td>
        <td class="cv-cell cv-yellow">5,1%</td>
        <td class="cv-cell cv-yellow">5,5%</td>
      </tr>
      <tr>
        <td>A5 Widerspruchserkennung</td>
        <td class="cv-cell cv-green">3,0%</td>
        <td class="cv-cell cv-yellow">10,7%</td>
        <td class="cv-cell cv-green" style="color:var(--accent)">0,6%*</td>
        <td class="cv-cell cv-yellow">13,0%</td>
      </tr>
      <tr>
        <td>A6 Zahlenanalyse</td>
        <td class="cv-cell cv-yellow">5,7%</td>
        <td class="cv-cell cv-yellow">6,6%</td>
        <td class="cv-cell cv-green">4,5%</td>
        <td class="cv-cell cv-yellow">10,7%</td>
      </tr>
      <tr style="background:#e8f4f8;font-weight:700">
        <td>Durchschnitt</td>
        <td style="color:var(--green)">3,9%</td>
        <td>6,2%</td>
        <td>5,4%</td>
        <td>8,8%</td>
      </tr>
    </table>
    <p style="font-size:0.85rem;color:var(--muted)">* Sonnet A5_P: CV=0,6% weil max_tokens-Limit bei jedem Run erreicht wird (4.096 Tokens exakt)</p>

    <h3>N-Variante (Normal-Prompt, nur A1–A4)</h3>
    <table>
      <tr>
        <th>Aufgabe</th>
        <th style="color:#f5a623">Opus 4.6</th>
        <th style="color:#b388ff">Opus 4.5</th>
        <th style="color:#64b5f6">Sonnet 4.5</th>
        <th style="color:#69f0ae">Haiku 4.5</th>
      </tr>
      <tr>
        <td>A1 Entscheidungsvorlage</td>
        <td class="cv-cell cv-yellow">5,4%</td>
        <td class="cv-cell cv-yellow">7,1%</td>
        <td class="cv-cell cv-yellow">9,7%</td>
        <td class="cv-cell cv-yellow">11,1%</td>
      </tr>
      <tr>
        <td>A2 Strateg. Zusammenfassung</td>
        <td class="cv-cell cv-yellow">10,3%</td>
        <td class="cv-cell cv-yellow">12,5%</td>
        <td class="cv-cell cv-yellow">5,9%</td>
        <td class="cv-cell cv-yellow">10,2%</td>
      </tr>
      <tr>
        <td>A3 Krit. Hinterfragen</td>
        <td class="cv-cell cv-yellow">11,6%</td>
        <td class="cv-cell cv-green">4,3%</td>
        <td class="cv-cell cv-yellow">12,9%</td>
        <td class="cv-cell cv-yellow">5,2%</td>
      </tr>
      <tr>
        <td>A4 Szenario-Analyse</td>
        <td class="cv-cell cv-red" style="font-weight:800">26,0%</td>
        <td class="cv-cell cv-yellow">6,9%</td>
        <td class="cv-cell cv-yellow">7,8%</td>
        <td class="cv-cell cv-yellow">14,3%</td>
      </tr>
      <tr style="background:#e8f4f8;font-weight:700">
        <td>Durchschnitt</td>
        <td style="color:var(--red)">13,3%</td>
        <td>7,7%</td>
        <td>9,1%</td>
        <td>10,2%</td>
      </tr>
    </table>

    <div class="highlight-box">
      <strong>Kernbefund Konsistenz:</strong><br>
      &bull; <strong>Opus 4.6 mit Power-Prompt ist das konsistenteste Modell</strong> (CV 3,9%) – es liefert
      bei 10 identischen Anfragen fast identische Antworten.<br>
      &bull; <strong>Ohne Power-Prompt wird Opus 4.6 am inkonsistentesten</strong> (CV 13,3%, davon A4_N mit 26%) –
      das Modell &bdquo;wandert&ldquo; ohne klare Anweisungen staerker als die anderen.<br>
      &bull; <strong>Power-Prompts stabilisieren alle Modelle:</strong> Der durchschnittliche CV sinkt von ~10%
      (N) auf ~6% (P). Gute Prompts machen Modelle nicht nur besser, sondern auch zuverlaessiger.
    </div>
  </div>
</section>

<!-- ==================== 9. AUFFAELLIGKEITEN ==================== -->
<section id="anomalien">
  <h2>9. Auffaelligkeiten &amp; Anomalien</h2>
  <div class="card">

    <div class="anomaly-card">
      <h4>Anomalie 1: Opus 4.6 A4_N – CV = 26%</h4>
      <p>Bei der Szenario-Analyse ohne System-Prompt schwankt Opus 4.6 stark. Die Antwortlaenge variiert
      zwischen ~4.500 und ~7.500 Zeichen. Ohne klare Strukturanweisung &bdquo;experimentiert&ldquo; das Modell
      mit unterschiedlichen Formaten und Detailtiefen. Mit Power-Prompt sinkt der CV auf 3,9% –
      <strong>Strukturanweisungen stabilisieren Opus 4.6 dramatisch.</strong></p>
    </div>

    <div class="anomaly-card">
      <h4>Anomalie 2: Sonnet 4.5 A5_P/A6_P – Token-Limit erreicht</h4>
      <p>Sonnet 4.5 produziert bei den dokumentenbasierten Aufgaben (A5, A6) so viel Output, dass das
      max_tokens-Limit von 4.096 bei jedem Run erreicht wird. Die Antworten brechen mitten im Satz ab.
      Bei A5_P ist der CV dadurch kuenstlich niedrig (0,6%). <strong>Empfehlung: max_tokens auf 8.192 erhoehen.</strong></p>
    </div>

    <div class="anomaly-card">
      <h4>Anomalie 3: A5_N/A6_N – 100% Fehlerquote</h4>
      <p>Die Normal-Varianten von A5 (Widerspruchserkennung) und A6 (Zahlenanalyse) scheitern bei allen Modellen.
      Grund: Die N-Variante sendet den vollen PDF-Text (>200.000 Tokens bei A5, >24.000 Input-Tokens bei A6).
      <strong>Das ist by design</strong> – es zeigt, dass dokumentenbasierte Aufgaben ohne Chunk-Strategie
      (P-Variante nutzt kuratierte Auszuege) nicht funktionieren.</p>
    </div>

    <div class="anomaly-card">
      <h4>Anomalie 4: Selbst-Bias im LLM-Judge</h4>
      <p>Opus 4.6 als Judge gibt sich selbst die hoechsten Scores (4,56 Avg.). Ein Stichproben-Test mit
      identischer Antwort zeigte: Opus 4.6 bewertet eigene Antworten ~0,3–0,5 Punkte hoeher als
      Fremd-Antworten vergleichbarer Qualitaet. <strong>Die Rangfolge ist voraussichtlich robust,
      die absoluten Scores sind moeglicherweise inflationaer.</strong> Cross-Judge-Validierung ausstehend.</p>
    </div>
  </div>
</section>

<!-- ==================== 10. FAZIT ==================== -->
<section id="fazit">
  <h2>10. Fazit &amp; Empfehlung</h2>
  <div class="card">

    <div class="grid-2">
      <div style="background:linear-gradient(135deg,#f0fdf4,#dcfce7);padding:20px;border-radius:10px;border:1px solid #86efac">
        <h4 style="color:#166534;margin-top:0">Fuer strategische Entscheidungen</h4>
        <p><span class="model-tag tag-opus46">Claude Opus 4.6</span></p>
        <p style="font-size:0.9rem">Score 4,56 – einziger &bdquo;Sparringspartner&ldquo;. Liefert auch ohne
        Power-Prompt tiefe Analysen. Identifiziert nicht-offensichtliche Zusammenhaenge. Ideal fuer
        M&A-Pruefungen, Strategiepapiere, Vertragsanalysen.</p>
        <p style="font-size:0.85rem;color:var(--muted)">Latenz: ~40s | Konsistenz (P): 3,9% CV</p>
      </div>
      <div style="background:linear-gradient(135deg,#eff6ff,#dbeafe);padding:20px;border-radius:10px;border:1px solid #93c5fd">
        <h4 style="color:#1e40af;margin-top:0">Fuer den taeglichen Einsatz</h4>
        <p><span class="model-tag tag-haiku">Claude Haiku 4.5</span></p>
        <p style="font-size:0.9rem">Score 4,21 – 92% der Qualitaet bei 48% der Latenz. Best Value.
        Ueberrascht bei Dokumentenvergleichen (A5: 4,75). Einzige Schwaeche: komplexe Szenario-Analysen (A4: 3,30).</p>
        <p style="font-size:0.85rem;color:var(--muted)">Latenz: ~19s | Konsistenz (P): 8,8% CV</p>
      </div>
    </div>

    <div style="margin-top:24px;background:linear-gradient(135deg,#faf5ff,#ede9fe);padding:20px;border-radius:10px;border:1px solid #c4b5fd">
      <h4 style="color:#5b21b6;margin-top:0">Und die anderen?</h4>
      <p><span class="model-tag tag-opus45">Opus 4.5</span> (Score 4,48): Sehr nah an Opus 4.6, gewinnt bei
      der Szenario-Analyse. Empfohlen wenn Opus 4.6 nicht verfuegbar ist.</p>
      <p><span class="model-tag tag-sonnet">Sonnet 4.5</span> (Score 4,31): Staerkste Urteilskraft-Tonalitaet,
      ideal fuer das &bdquo;ehrliche Feedback&ldquo;. Leidet unter Token-Limit – mit 8.192 max_tokens
      voraussichtlich bessere Ergebnisse.</p>
    </div>

    <div class="highlight-box" style="margin-top:24px">
      <h4 style="margin-top:0;color:var(--accent)">Die wichtigste Erkenntnis fuer Entscheider:</h4>
      <p style="font-size:1.1rem;font-weight:600;margin-bottom:8px">
        &bdquo;Nicht welches Modell du nutzt, sondern wie du es nutzt, macht den Unterschied.&ldquo;
      </p>
      <p>Power-Prompts verdoppeln den Output, stabilisieren die Konsistenz und erhoehen die Qualitaet.
      Ein gut promptender GF mit Haiku 4.5 (dem guenstigsten Modell) kommt weiter als ein schlecht promptender
      GF mit Opus 4.6 (dem teuersten). <strong>Prompt-Kompetenz ist der staerkste Hebel – staerker als die Modellwahl.</strong></p>
    </div>
  </div>
</section>

<!-- ==================== 11. TRANSPARENZ ==================== -->
<section id="transparenz">
  <h2>11. Transparenz &amp; Limitationen</h2>
  <div class="card">
    <p>Dieser Benchmark benennt seine Grenzen explizit – das unterscheidet ihn von Marketing-Benchmarks.</p>

    <table>
      <tr><th style="width:40px">#</th><th>Limitation</th><th>Auswirkung</th></tr>
      <tr>
        <td>1</td>
        <td><strong>Nur Anthropic-Modelle</strong></td>
        <td>Vergleich mit GPT-5.2, Gemini, Grok etc. steht aus (OpenRouter-Credits noetig)</td>
      </tr>
      <tr>
        <td>2</td>
        <td><strong>Selbst-Bias im Judge</strong></td>
        <td>Opus 4.6 bewertet sich selbst – Cross-Judge-Validierung ausstehend</td>
      </tr>
      <tr>
        <td>3</td>
        <td><strong>6 Aufgabenkategorien</strong></td>
        <td>Nicht repraesentativ fuer alle Fuehrungsaufgaben (z.B. kein HR, kein Legal)</td>
      </tr>
      <tr>
        <td>4</td>
        <td><strong>Einzelbewerter (LLM)</strong></td>
        <td>Manuelle Kalibrierung durch Gerald noch ausstehend (Inter-Rater-Agreement)</td>
      </tr>
      <tr>
        <td>5</td>
        <td><strong>DACH-Fokus</strong></td>
        <td>Szenarien, Sprache und Regulatorik oesterreichisch/deutsch – nicht global uebertragbar</td>
      </tr>
      <tr>
        <td>6</td>
        <td><strong>Statischer Zeitpunkt</strong></td>
        <td>Stand 07.02.2026 – Modelle werden laufend aktualisiert</td>
      </tr>
      <tr>
        <td>7</td>
        <td><strong>Keine Kosten-Normalisierung</strong></td>
        <td>Opus 4.6 kostet ein Vielfaches von Haiku – Score sagt nichts ueber ROI</td>
      </tr>
      <tr>
        <td>8</td>
        <td><strong>Kein Tool-Use</strong></td>
        <td>Reines Text-in/Text-out – Web-Search, Code, Datei-Analyse deaktiviert</td>
      </tr>
    </table>

    <h3>Naechste Schritte</h3>
    <table>
      <tr><th>Schritt</th><th>Status</th><th>Blocker</th></tr>
      <tr><td>OpenAI-Modelle (GPT-5.2, o1) testen</td><td>4/10 Runs OK</td><td>OpenRouter Credits leer</td></tr>
      <tr><td>Google-Modelle (Gemini 3 Pro, 2.5 Pro/Flash) testen</td><td>Flash OK, Rest blockiert</td><td>Quota / Model-ID</td></tr>
      <tr><td>OpenRouter-Modelle (Grok, Mistral, DeepSeek, Llama) testen</td><td>Ausstehend</td><td>Credits</td></tr>
      <tr><td>Cross-Judge-Validierung (GPT-5.2 bewertet Anthropic)</td><td>Ausstehend</td><td>Credits</td></tr>
      <tr><td>Manuelle Kalibrierung (Gerald: 5–6 Antworten)</td><td>Ausstehend</td><td>Zeit</td></tr>
      <tr><td>Inter-Rater-Agreement (Cohen's Kappa)</td><td>Ausstehend</td><td>Manuelle Bewertung</td></tr>
    </table>

    <h3>Reproduzierbarkeit</h3>
    <p>Jeder kann diesen Benchmark nachvollziehen:</p>
    <ul style="padding-left:20px">
      <li>Alle Prompts sind im Repository dokumentiert</li>
      <li>Temperatur 0, identische Bedingungen fuer alle Modelle</li>
      <li>Audit-Trail: 3 Dateien pro API-Call (Prompt, Antwort, Raw-JSON)</li>
      <li>Git-Hash und Dokument-Checksummen in run_meta.json</li>
      <li>Python-Scripts (benchmark.py, evaluate.py, analyze.py) oeffentlich</li>
    </ul>
  </div>
</section>

</div><!-- /container -->

<!-- ==================== FOOTER ==================== -->
<div class="footer">
  <div class="container">
    <p><strong>Entscheider-Benchmark 2026</strong> – Gerald T. Poegl | Hunter-ID MemoryBlock BG FlexCo</p>
    <p>HID-LINKEDIN-BENCHMARK-2026-02-06-ACTIVE-C4E8A1-CLO46</p>
    <p style="margin-top:12px;opacity:0.7">
      Benchmark-Infrastruktur: Python 3.11+ | Multi-Provider-Architektur | Temperature 0 | 10 Runs pro Modell × Aufgabe<br>
      Qualitaetsbewertung: LLM-as-a-Judge (Claude Opus 4.6) | 5 Kriterien | Gewichteter Score<br>
      Alle Daten, Prompts und Scripts sind reproduzierbar dokumentiert.
    </p>
    <p style="margin-top:16px;opacity:0.5;font-size:0.8rem">&copy; 2026 Gerald T. Poegl. Alle Rechte vorbehalten.</p>
  </div>
</div>

</body>
</html>